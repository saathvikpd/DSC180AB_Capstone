{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181938a6-bc3d-4426-9568-36c7a651ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446b6a1e-5ebb-4f1c-a978-bd96929dc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from gptq import GPTQ\n",
    "\n",
    "# Define a small neural network\n",
    "class SmallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Function to quantize all layers in the model with layer-specific inputs\n",
    "def quantize_model_with_propagation(model, input_data, bits=4):\n",
    "    activations = input_data  # Start with the original input\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            print(f\"Quantizing layer: {name}\")\n",
    "            gptq = GPTQ(layer, bits=bits)\n",
    "            \n",
    "            # Add activations (layer-specific inputs) for Hessian calculation\n",
    "            gptq.add_batch(activations.detach().cpu().numpy())\n",
    "            gptq.quantize()  # Perform GPTQ-based quantization\n",
    "            \n",
    "            # Replace the original weights with quantized weights\n",
    "            layer.weight.data = torch.tensor(gptq.get_quantized_weights(), dtype=layer.weight.dtype)\n",
    "            if layer.bias is not None:\n",
    "                layer.bias.data = torch.tensor(gptq.get_quantized_bias(), dtype=layer.bias.dtype)\n",
    "            print(f\"Layer {name} quantized successfully.\\n\")\n",
    "            \n",
    "            # Forward pass through the quantized layer to get new activations\n",
    "            with torch.no_grad():\n",
    "                activations = torch.relu(layer(activations))  # Update activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede4f724-2307-4a77-8451-33cc7994cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate training data\n",
    "def generate_data(samples=1000, features=num_features):\n",
    "    x = np.random.rand(samples, features).astype(np.float32)\n",
    "    y = np.mean(x, axis=1, keepdims=True).astype(np.float32)\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "x_train, y_train = generate_data(samples=1000)\n",
    "x_test, y_test = generate_data(samples=200)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e2e6c9-d293-40ae-857d-9b614ba3ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1781\n",
      "Epoch [2/10], Loss: 0.0579\n",
      "Epoch [3/10], Loss: 0.0354\n",
      "Epoch [4/10], Loss: 0.0284\n",
      "Epoch [5/10], Loss: 0.0176\n",
      "Epoch [6/10], Loss: 0.0062\n",
      "Epoch [7/10], Loss: 0.0015\n",
      "Epoch [8/10], Loss: 0.0009\n",
      "Epoch [9/10], Loss: 0.0006\n",
      "Epoch [10/10], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# Train the SmallNet to learn the mean function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daef4f16-0073-4ef3-97c2-e756e3929468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc6dccc-ec46-4721-aed8-c1a776341dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the original model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    original_outputs = []\n",
    "    for x_batch, _ in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        original_outputs.append(model(x_batch))\n",
    "\n",
    "# Concatenate original outputs for comparison\n",
    "original_outputs = torch.cat(original_outputs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ecb8ab0-486d-45fb-a913-790436f60287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer: fc1\n",
      "Estimating Hessian diagonal for layer with shape (20, 2)...\n",
      "Hessian diagonal estimated.\n",
      "Starting GPTQ quantization for layer with shape (20, 2)...\n",
      "GPTQ quantization using Cholesky inverse completed.\n",
      "Layer fc1 quantized successfully.\n",
      "\n",
      "Quantizing layer: fc2\n",
      "Estimating Hessian diagonal for layer with shape (30, 20)...\n",
      "Hessian diagonal estimated.\n",
      "Starting GPTQ quantization for layer with shape (30, 20)...\n",
      "Hessian is not positive definite. Falling back to diagonal inverse.\n",
      "GPTQ quantization using Cholesky inverse completed.\n",
      "Layer fc2 quantized successfully.\n",
      "\n",
      "Quantizing layer: fc3\n",
      "Estimating Hessian diagonal for layer with shape (20, 30)...\n",
      "Hessian diagonal estimated.\n",
      "Starting GPTQ quantization for layer with shape (20, 30)...\n",
      "Hessian is not positive definite. Falling back to diagonal inverse.\n",
      "GPTQ quantization using Cholesky inverse completed.\n",
      "Layer fc3 quantized successfully.\n",
      "\n",
      "Quantizing layer: fc4\n",
      "Estimating Hessian diagonal for layer with shape (1, 20)...\n",
      "Hessian diagonal estimated.\n",
      "Starting GPTQ quantization for layer with shape (1, 20)...\n",
      "Hessian is not positive definite. Falling back to diagonal inverse.\n",
      "GPTQ quantization using Cholesky inverse completed.\n",
      "Layer fc4 quantized successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = SmallNet()\n",
    "model.eval()\n",
    "\n",
    "# Create dummy input data\n",
    "dummy_input = torch.randn(100, 2)  # 100 samples, 10 features\n",
    "\n",
    "# Quantize all layers in the model\n",
    "quantize_model_with_propagation(model, dummy_input, bits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df7dcda-3939-4c7c-a6ac-54c957d8fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the quantized model\n",
    "with torch.no_grad():\n",
    "    quantized_outputs = []\n",
    "    for x_batch, _ in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        quantized_outputs.append(model(x_batch))\n",
    "\n",
    "# Concatenate quantized outputs for comparison\n",
    "quantized_outputs = torch.cat(quantized_outputs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9a7e8c-603b-495d-a3d7-5188ad524767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) between original and quantized outputs: 0.44415464997291565\n"
     ]
    }
   ],
   "source": [
    "# Compute Mean Squared Error (MSE)\n",
    "mse = torch.mean((original_outputs - quantized_outputs) ** 2)\n",
    "print(\"Mean Squared Error (MSE) between original and quantized outputs:\", mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a48dc1-da31-4850-99bb-f0e502a9cf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.9018]), tensor([-0.1396])),\n",
       " (tensor([0.2360]), tensor([-0.1674])),\n",
       " (tensor([0.5717]), tensor([-0.1489])),\n",
       " (tensor([0.4785]), tensor([-0.1557])),\n",
       " (tensor([0.6948]), tensor([-0.1459])),\n",
       " (tensor([0.1646]), tensor([-0.1736])),\n",
       " (tensor([0.8627]), tensor([-0.1407])),\n",
       " (tensor([0.3160]), tensor([-0.1645])),\n",
       " (tensor([0.7842]), tensor([-0.1432])),\n",
       " (tensor([0.2346]), tensor([-0.1666])),\n",
       " (tensor([0.2289]), tensor([-0.1691])),\n",
       " (tensor([0.5551]), tensor([-0.1504])),\n",
       " (tensor([0.3892]), tensor([-0.1612])),\n",
       " (tensor([0.4153]), tensor([-0.1594])),\n",
       " (tensor([0.2706]), tensor([-0.1642])),\n",
       " (tensor([0.2444]), tensor([-0.1675])),\n",
       " (tensor([0.4993]), tensor([-0.1549])),\n",
       " (tensor([0.2443]), tensor([-0.1662])),\n",
       " (tensor([0.1657]), tensor([-0.1722])),\n",
       " (tensor([0.7272]), tensor([-0.1448])),\n",
       " (tensor([0.3481]), tensor([-0.1615])),\n",
       " (tensor([0.7397]), tensor([-0.1467])),\n",
       " (tensor([0.5269]), tensor([-0.1547])),\n",
       " (tensor([0.8105]), tensor([-0.1425])),\n",
       " (tensor([0.3670]), tensor([-0.1619])),\n",
       " (tensor([0.7173]), tensor([-0.1481])),\n",
       " (tensor([0.6971]), tensor([-0.1494])),\n",
       " (tensor([0.2397]), tensor([-0.1643])),\n",
       " (tensor([0.4008]), tensor([-0.1580])),\n",
       " (tensor([0.4403]), tensor([-0.1564])),\n",
       " (tensor([0.4161]), tensor([-0.1490])),\n",
       " (tensor([0.6039]), tensor([-0.1495])),\n",
       " (tensor([0.6784]), tensor([-0.1467])),\n",
       " (tensor([0.8663]), tensor([-0.1427])),\n",
       " (tensor([0.7486]), tensor([-0.1481])),\n",
       " (tensor([0.6440]), tensor([-0.1527])),\n",
       " (tensor([0.4589]), tensor([-0.1524])),\n",
       " (tensor([0.4606]), tensor([-0.1550])),\n",
       " (tensor([0.4351]), tensor([-0.1593])),\n",
       " (tensor([0.6058]), tensor([-0.1443])),\n",
       " (tensor([0.4865]), tensor([-0.1548])),\n",
       " (tensor([0.7707]), tensor([-0.1436])),\n",
       " (tensor([0.1810]), tensor([-0.1719])),\n",
       " (tensor([0.4749]), tensor([-0.1553])),\n",
       " (tensor([0.1636]), tensor([-0.1752])),\n",
       " (tensor([0.6312]), tensor([-0.1498])),\n",
       " (tensor([0.3361]), tensor([-0.1602])),\n",
       " (tensor([0.6123]), tensor([-0.1532])),\n",
       " (tensor([0.6237]), tensor([-0.1463])),\n",
       " (tensor([0.8034]), tensor([-0.1425])),\n",
       " (tensor([0.5161]), tensor([-0.1563])),\n",
       " (tensor([0.6488]), tensor([-0.1530])),\n",
       " (tensor([0.7621]), tensor([-0.1444])),\n",
       " (tensor([0.5508]), tensor([-0.1507])),\n",
       " (tensor([0.4759]), tensor([-0.1460])),\n",
       " (tensor([0.4329]), tensor([-0.1511])),\n",
       " (tensor([0.3544]), tensor([-0.1608])),\n",
       " (tensor([0.3146]), tensor([-0.1619])),\n",
       " (tensor([0.3537]), tensor([-0.1626])),\n",
       " (tensor([0.5316]), tensor([-0.1516])),\n",
       " (tensor([0.5139]), tensor([-0.1482])),\n",
       " (tensor([0.2672]), tensor([-0.1656])),\n",
       " (tensor([0.2502]), tensor([-0.1684])),\n",
       " (tensor([0.3218]), tensor([-0.1642])),\n",
       " (tensor([0.5316]), tensor([-0.1520])),\n",
       " (tensor([0.3977]), tensor([-0.1591])),\n",
       " (tensor([0.9217]), tensor([-0.1399])),\n",
       " (tensor([0.3448]), tensor([-0.1539])),\n",
       " (tensor([0.4428]), tensor([-0.1592])),\n",
       " (tensor([0.5223]), tensor([-0.1542])),\n",
       " (tensor([0.4112]), tensor([-0.1595])),\n",
       " (tensor([0.1628]), tensor([-0.1729])),\n",
       " (tensor([0.3408]), tensor([-0.1631])),\n",
       " (tensor([0.5927]), tensor([-0.1498])),\n",
       " (tensor([0.3771]), tensor([-0.1589])),\n",
       " (tensor([0.3234]), tensor([-0.1646])),\n",
       " (tensor([0.5435]), tensor([-0.1559])),\n",
       " (tensor([0.5318]), tensor([-0.1552])),\n",
       " (tensor([0.6753]), tensor([-0.1496])),\n",
       " (tensor([0.7438]), tensor([-0.1470])),\n",
       " (tensor([0.4780]), tensor([-0.1583])),\n",
       " (tensor([0.4987]), tensor([-0.1544])),\n",
       " (tensor([0.4565]), tensor([-0.1595])),\n",
       " (tensor([0.3938]), tensor([-0.1588])),\n",
       " (tensor([0.6707]), tensor([-0.1521])),\n",
       " (tensor([0.2244]), tensor([-0.1679])),\n",
       " (tensor([0.1606]), tensor([-0.1743])),\n",
       " (tensor([0.5096]), tensor([-0.1568])),\n",
       " (tensor([0.2375]), tensor([-0.1672])),\n",
       " (tensor([0.5898]), tensor([-0.1438])),\n",
       " (tensor([0.4316]), tensor([-0.1564])),\n",
       " (tensor([0.8104]), tensor([-0.1424])),\n",
       " (tensor([0.9017]), tensor([-0.1399])),\n",
       " (tensor([0.6370]), tensor([-0.1484])),\n",
       " (tensor([0.2588]), tensor([-0.1657])),\n",
       " (tensor([0.9120]), tensor([-0.1410])),\n",
       " (tensor([0.3819]), tensor([-0.1539])),\n",
       " (tensor([0.3916]), tensor([-0.1555])),\n",
       " (tensor([0.5111]), tensor([-0.1568])),\n",
       " (tensor([0.7206]), tensor([-0.1471])),\n",
       " (tensor([0.6662]), tensor([-0.1496])),\n",
       " (tensor([0.6314]), tensor([-0.1480])),\n",
       " (tensor([0.6328]), tensor([-0.1502])),\n",
       " (tensor([0.2354]), tensor([-0.1666])),\n",
       " (tensor([0.6803]), tensor([-0.1471])),\n",
       " (tensor([0.4951]), tensor([-0.1542])),\n",
       " (tensor([0.4703]), tensor([-0.1587])),\n",
       " (tensor([0.5422]), tensor([-0.1533])),\n",
       " (tensor([0.7262]), tensor([-0.1454])),\n",
       " (tensor([0.4149]), tensor([-0.1583])),\n",
       " (tensor([0.4909]), tensor([-0.1583])),\n",
       " (tensor([0.4165]), tensor([-0.1482])),\n",
       " (tensor([0.4464]), tensor([-0.1556])),\n",
       " (tensor([0.7056]), tensor([-0.1466])),\n",
       " (tensor([0.1556]), tensor([-0.1778])),\n",
       " (tensor([0.1587]), tensor([-0.1771])),\n",
       " (tensor([0.4193]), tensor([-0.1594])),\n",
       " (tensor([0.1544]), tensor([-0.1792])),\n",
       " (tensor([0.3476]), tensor([-0.1609])),\n",
       " (tensor([0.3137]), tensor([-0.1627])),\n",
       " (tensor([0.4417]), tensor([-0.1590])),\n",
       " (tensor([0.1662]), tensor([-0.1715])),\n",
       " (tensor([0.1749]), tensor([-0.1736])),\n",
       " (tensor([0.6027]), tensor([-0.1493])),\n",
       " (tensor([0.7480]), tensor([-0.1443])),\n",
       " (tensor([0.5046]), tensor([-0.1486])),\n",
       " (tensor([0.3097]), tensor([-0.1651])),\n",
       " (tensor([0.2114]), tensor([-0.1671])),\n",
       " (tensor([0.2064]), tensor([-0.1694])),\n",
       " (tensor([0.4349]), tensor([-0.1563])),\n",
       " (tensor([0.7521]), tensor([-0.1470])),\n",
       " (tensor([0.9006]), tensor([-0.1398])),\n",
       " (tensor([0.6583]), tensor([-0.1481])),\n",
       " (tensor([0.7196]), tensor([-0.1455])),\n",
       " (tensor([0.3498]), tensor([-0.1606])),\n",
       " (tensor([0.2980]), tensor([-0.1629])),\n",
       " (tensor([0.6793]), tensor([-0.1469])),\n",
       " (tensor([0.7816]), tensor([-0.1447])),\n",
       " (tensor([0.2276]), tensor([-0.1673])),\n",
       " (tensor([0.5033]), tensor([-0.1535])),\n",
       " (tensor([0.5715]), tensor([-0.1494])),\n",
       " (tensor([0.5617]), tensor([-0.1501])),\n",
       " (tensor([0.4798]), tensor([-0.1576])),\n",
       " (tensor([0.8942]), tensor([-0.1398])),\n",
       " (tensor([0.9273]), tensor([-0.1396])),\n",
       " (tensor([0.6238]), tensor([-0.1490])),\n",
       " (tensor([0.5320]), tensor([-0.1571])),\n",
       " (tensor([0.6082]), tensor([-0.1500])),\n",
       " (tensor([0.5042]), tensor([-0.1568])),\n",
       " (tensor([0.7673]), tensor([-0.1442])),\n",
       " (tensor([0.3208]), tensor([-0.1642])),\n",
       " (tensor([0.5725]), tensor([-0.1498])),\n",
       " (tensor([0.6701]), tensor([-0.1511])),\n",
       " (tensor([0.6325]), tensor([-0.1527])),\n",
       " (tensor([0.3688]), tensor([-0.1618])),\n",
       " (tensor([0.1605]), tensor([-0.1748])),\n",
       " (tensor([0.1925]), tensor([-0.1694])),\n",
       " (tensor([0.3128]), tensor([-0.1624])),\n",
       " (tensor([0.3341]), tensor([-0.1605])),\n",
       " (tensor([0.1612]), tensor([-0.1742])),\n",
       " (tensor([0.6094]), tensor([-0.1486])),\n",
       " (tensor([0.2133]), tensor([-0.1705])),\n",
       " (tensor([0.3210]), tensor([-0.1619])),\n",
       " (tensor([0.3082]), tensor([-0.1626])),\n",
       " (tensor([0.5288]), tensor([-0.1555])),\n",
       " (tensor([0.5423]), tensor([-0.1417])),\n",
       " (tensor([0.3150]), tensor([-0.1643])),\n",
       " (tensor([0.5953]), tensor([-0.1454])),\n",
       " (tensor([0.3735]), tensor([-0.1618])),\n",
       " (tensor([0.5792]), tensor([-0.1505])),\n",
       " (tensor([0.3853]), tensor([-0.1593])),\n",
       " (tensor([0.1925]), tensor([-0.1718])),\n",
       " (tensor([0.3786]), tensor([-0.1599])),\n",
       " (tensor([0.7517]), tensor([-0.1455])),\n",
       " (tensor([0.4173]), tensor([-0.1570])),\n",
       " (tensor([0.1710]), tensor([-0.1741])),\n",
       " (tensor([0.4423]), tensor([-0.1533])),\n",
       " (tensor([0.3791]), tensor([-0.1620])),\n",
       " (tensor([0.6912]), tensor([-0.1481])),\n",
       " (tensor([0.4019]), tensor([-0.1579])),\n",
       " (tensor([0.5930]), tensor([-0.1492])),\n",
       " (tensor([0.5779]), tensor([-0.1546])),\n",
       " (tensor([0.5138]), tensor([-0.1533])),\n",
       " (tensor([0.4066]), tensor([-0.1487])),\n",
       " (tensor([0.3656]), tensor([-0.1603])),\n",
       " (tensor([0.3616]), tensor([-0.1610])),\n",
       " (tensor([0.3398]), tensor([-0.1625])),\n",
       " (tensor([0.2826]), tensor([-0.1670])),\n",
       " (tensor([0.9319]), tensor([-0.1401])),\n",
       " (tensor([0.4513]), tensor([-0.1556])),\n",
       " (tensor([0.7549]), tensor([-0.1444])),\n",
       " (tensor([0.5079]), tensor([-0.1528])),\n",
       " (tensor([0.1615]), tensor([-0.1754])),\n",
       " (tensor([0.5050]), tensor([-0.1560])),\n",
       " (tensor([0.3602]), tensor([-0.1604])),\n",
       " (tensor([0.2941]), tensor([-0.1645])),\n",
       " (tensor([0.6172]), tensor([-0.1490])),\n",
       " (tensor([0.5089]), tensor([-0.1532])),\n",
       " (tensor([0.5857]), tensor([-0.1499])),\n",
       " (tensor([0.3317]), tensor([-0.1629]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(original_outputs, quantized_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ad1d2-b337-41d6-b7a4-a806ba755734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c145e-c411-4b0e-bffa-5b1aeeacc884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
